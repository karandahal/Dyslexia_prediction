{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Import packages**"],"metadata":{"id":"PGu0dk0xAjmN"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"_Ydidon97Upw","executionInfo":{"status":"ok","timestamp":1731686657091,"user_tz":-480,"elapsed":391,"user":{"displayName":"蕭俊煒","userId":"16565834763599032470"}}},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_absolute_error, f1_score, accuracy_score\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","source":["**Data Preprocessing**"],"metadata":{"id":"Ytb1epXaAwcq"}},{"cell_type":"code","source":["# Load data\n","data = pd.read_csv('labelled_dysx.csv')\n","y = data['Label']\n","X = data.drop(['Label'], axis=1)\n","columns = X.columns  # Get feature names\n","\n","# Define test samples as DataFrames with proper feature names\n","test1 = pd.DataFrame([[0.5, 0.1, 0.2, 0.8, 0.3, 0.5]], columns=columns)\n","test2 = pd.DataFrame([[0.7, 0.9, 0.4, 0.9, 0.3, 0.8]], columns=columns)\n","test3 = pd.DataFrame([[0.1, 0.7, 0.2, 0.6, 0.9, 0.6]], columns=columns)\n","test4 = pd.DataFrame([[0.3, 0.4, 0.5, 0.3, 0.3, 0.5]], columns=columns)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n","\n","# Initialize label lists for storing predictions (optional initialization for multiple models)\n","label_1 = [0, 0, 0, 0, 0]\n","label_2 = [0, 0, 0, 0, 0]\n","label_3 = [0, 0, 0, 0, 0]\n","label_4 = [0, 0, 0, 0, 0]\n","\n","# Scale data\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","test1 = sc.transform(test1)\n","test2 = sc.transform(test2)\n","test3 = sc.transform(test3)\n","test4 = sc.transform(test4)"],"metadata":{"id":"h0tb0_ml7r8B","executionInfo":{"status":"ok","timestamp":1731686660016,"user_tz":-480,"elapsed":294,"user":{"displayName":"蕭俊煒","userId":"16565834763599032470"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["**Training model - Random Forest with GridSearchSV**"],"metadata":{"id":"eiZYBdYsNHJl"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import mean_absolute_error, f1_score, accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","\n","# -------------------------\n","# Step 1: Data Preprocessing\n","# -------------------------\n","\n","# Load data\n","data = pd.read_csv('labelled_dysx.csv')\n","y = data['Label']\n","X = data.drop(['Label'], axis=1)\n","columns = X.columns  # Get feature names\n","\n","# Define test samples as DataFrames with proper feature names\n","test1 = pd.DataFrame([[0.5, 0.1, 0.2, 0.8, 0.3, 0.5]], columns=columns)\n","test2 = pd.DataFrame([[0.7, 0.9, 0.4, 0.9, 0.3, 0.8]], columns=columns)\n","test3 = pd.DataFrame([[0.1, 0.7, 0.2, 0.6, 0.9, 0.6]], columns=columns)\n","test4 = pd.DataFrame([[0.3, 0.4, 0.5, 0.3, 0.3, 0.5]], columns=columns)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n","\n","# Initialize label lists for storing predictions\n","label_1 = [0, 0, 0, 0, 0]\n","label_2 = [0, 0, 0, 0, 0]\n","label_3 = [0, 0, 0, 0, 0]\n","label_4 = [0, 0, 0, 0, 0]\n","\n","# Scale data\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","test1 = sc.transform(test1)\n","test2 = sc.transform(test2)\n","test3 = sc.transform(test3)\n","test4 = sc.transform(test4)\n","\n","# -------------------------\n","# Step 2: Model Training and Evaluation\n","# -------------------------\n","\n","# Random Forest with GridSearchCV for hyperparameter tuning\n","n_est = {'n_estimators': [10, 100, 500, 1000]}\n","rf_grid = GridSearchCV(RandomForestClassifier(random_state=0), n_est, scoring='f1_macro')\n","rf_grid.fit(X_train, y_train)\n","\n","# Print the best parameters\n","print('Best value of n_estimators for RandomForest model is:', rf_grid.best_params_)\n","\n","# Evaluate model on test data and store error metrics\n","pred_rf_grid = rf_grid.predict(X_test)\n","test_error = round(mean_absolute_error(y_test, pred_rf_grid), 3)\n","test_f1 = round(f1_score(y_test, pred_rf_grid, average='macro'), 3)\n","test_accuracy = round(accuracy_score(y_test, pred_rf_grid), 3)\n","\n","print('Metrics on Test Set:')\n","print(f'Mean Absolute Error: {test_error}')\n","print(f'F1 Score: {test_f1}')\n","print(f'Accuracy: {test_accuracy}')\n","\n","# Make predictions on validation samples\n","ans_1 = rf_grid.predict(test1)\n","ans_2 = rf_grid.predict(test2)\n","ans_3 = rf_grid.predict(test3)\n","ans_4 = rf_grid.predict(test4)\n","\n","# Store predictions in respective label lists at the RandomForest(GridSearch) index\n","label_1[3] = ans_1[0]\n","label_2[3] = ans_2[0]\n","label_3[3] = ans_3[0]\n","label_4[3] = ans_4[0]\n","\n","# Print predictions for each validation sample\n","print('\\nPredicted Labels for Validation Samples:')\n","print('Labels for test1:', label_1)\n","print('Labels for test2:', label_2)\n","print('Labels for test3:', label_3)\n","print('Labels for test4:', label_4)\n","\n","# Optional: Calculate and print F1 score and accuracy on the validation samples\n","# (assuming the actual labels for these samples are known, replace 'actual_label' accordingly)\n","\n","# Placeholder actual labels for demonstration purposes (replace with real labels if available)\n","actual_labels = [1, 0, 1, 0]  # Replace these with the real labels of test1, test2, test3, test4\n","predictions = [label_1[3], label_2[3], label_3[3], label_4[3]]\n","\n","validation_f1 = round(f1_score(actual_labels, predictions, average='macro'), 3)\n","validation_accuracy = round(accuracy_score(actual_labels, predictions), 3)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pHjPBHsDBcTA","executionInfo":{"status":"ok","timestamp":1731686752651,"user_tz":-480,"elapsed":15440,"user":{"displayName":"蕭俊煒","userId":"16565834763599032470"}},"outputId":"32771c81-998f-44fc-d147-3ca7b7da34e8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Best value of n_estimators for RandomForest model is: {'n_estimators': 100}\n","Metrics on Test Set:\n","Mean Absolute Error: 0.04\n","F1 Score: 0.965\n","Accuracy: 0.96\n","\n","Predicted Labels for Validation Samples:\n","Labels for test1: [0, 0, 0, 0, 0]\n","Labels for test2: [0, 0, 0, 2, 0]\n","Labels for test3: [0, 0, 0, 0, 0]\n","Labels for test4: [0, 0, 0, 1, 0]\n"]}]}]}